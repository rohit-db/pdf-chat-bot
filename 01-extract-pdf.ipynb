{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "786212c9-9619-4b9c-a5f1-b9cddf7f333d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d458ab2-dcf3-4e45-aeb2-8e4c34b26202",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.sdk import WorkspaceClient\n",
    "from databricks.sdk.service.workspace import ExportFormat\n",
    "import os\n",
    "import base64\n",
    "import logging\n",
    "\n",
    "def create_catalog_schema_volume(spark, catalog_name, schema_name, volume_name):\n",
    "    try:\n",
    "        spark.sql(f\"CREATE CATALOG IF NOT EXISTS {catalog_name}\")\n",
    "        spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {catalog_name}.{schema_name}\")\n",
    "        spark.sql(f\"CREATE VOLUME IF NOT EXISTS {catalog_name}.{schema_name}.{volume_name}\")\n",
    "        logging.info(\"Catalog, schema, and volume created successfully.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error creating catalog, schema, or volume: {e}\")\n",
    "        raise\n",
    "\n",
    "def export_and_upload_files(workspace_folder, volume_path):\n",
    "    w = WorkspaceClient()\n",
    "    source_files = f\"{volume_path}/original\"\n",
    "\n",
    "    try:\n",
    "        items = w.workspace.list(workspace_folder)\n",
    "        for item in items:\n",
    "            if item.object_type.name == \"FILE\":\n",
    "                file_path = item.path\n",
    "                file_name = os.path.basename(file_path)\n",
    "\n",
    "                logging.info(f\"Exporting {file_path} into memory...\")\n",
    "\n",
    "                export_response = w.workspace.export(path=file_path, format=ExportFormat.AUTO)\n",
    "                file_content = base64.b64decode(export_response.content)\n",
    "\n",
    "                with open(f\"{source_files}/{file_name}\", \"wb\") as f:\n",
    "                    f.write(file_content)\n",
    "\n",
    "                logging.info(f\"Written {file_name} into {volume_path}\")\n",
    "\n",
    "        logging.info(\"All files successfully written to Volume!\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error exporting or uploading files: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "30df04e4-dede-4d88-9eda-8ae19e580428",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.text(\"catalog_name\", \"rohitb_demo\")\n",
    "dbutils.widgets.text(\"schema_name\", \"pdf_chat\")\n",
    "dbutils.widgets.text(\"volume_name\", \"files\")\n",
    "dbutils.widgets.text(\"workspace_folder\", \"/Workspace/Users/rohit.bhagwat@databricks.com/pdf-chat-bot/data\")\n",
    "\n",
    "catalog_name = dbutils.widgets.get(\"catalog_name\")\n",
    "schema_name = dbutils.widgets.get(\"schema_name\")\n",
    "volume_name = dbutils.widgets.get(\"volume_name\")\n",
    "workspace_folder = dbutils.widgets.get(\"workspace_folder\")\n",
    "\n",
    "volume_path = f\"/Volumes/{catalog_name}/{schema_name}/{volume_name}\"\n",
    "local_tmp_dir = \"/dbfs/tmp/pdf-chat-bot-data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "55c81497-46f3-4272-ba8b-032208f18ea1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Parse PDF Files using Databricks Document Parsing\n",
    "\n",
    "##Background \n",
    "Databricks is previewing Document Parsing, which extracts structured content from unstructured documents. This unlocks the full potential of data that’s currently trapped in unusable formats (e.g., scanned images)—automatically preparing it for a wide variety of analytic and AI use cases. You can use it ad hoc or in a continuous pipeline. \n",
    "\n",
    "Specifically, this preview provides three user-defined functions (UDFs):  \n",
    "`ai_parse` extracts the contextual layout metadata from the document (e.g., title, header, footer). It also extracts the content of the document (e.g., text paragraphs, tables) and represents it in text and markdown format.   \n",
    "`ai_extract_table_schema` extracts the schema from the document, represented as a STRING.  \n",
    "`ai_extract_table_data` extracts the table data from the document, represented as a STRUCT.  \n",
    "\n",
    "If you’re building a RAG or Vector Search application, then Databricks recommends `ai_parse` because the output format caters to these use cases. But if you have a use case that requires a structured table, then Databricks recommends `ai_extract_table_schema` and `ai_extract_table_data`.\n",
    "\n",
    "In general, `ai_parse` is more performant for larger documents because it can process each page in parallel. However, it also requires more compute because it makes multiple calls per document.\n",
    "\n",
    "Note\n",
    "The connector is currently powered by third-party models hosted by Azure OpenAI.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e553bd4-e191-4bd3-bfd1-f1eb1d7622ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "# Create catalog, schema, and volume\n",
    "create_catalog_schema_volume(spark, catalog_name, schema_name, volume_name)\n",
    "\n",
    "# Export and upload files\n",
    "export_and_upload_files(workspace_folder, volume_path)\n",
    "\n",
    "# Process the files using ai_parse().\n",
    "df = spark.sql(\n",
    "    f\"\"\"\n",
    "        WITH corpus AS (\n",
    "          SELECT\n",
    "            path,\n",
    "            ai_parse(content, map('format', 'pdf')) AS parsed\n",
    "          FROM\n",
    "            READ_FILES('{volume_path}/original/*', format => 'binaryFile')\n",
    "        )\n",
    "        SELECT\n",
    "          path,\n",
    "          parsed,\n",
    "          parsed:document AS document,\n",
    "          parsed:pages AS pages,\n",
    "          parsed:elements AS elements,\n",
    "          parsed:_corrupted_data AS _corrupted_data\n",
    "        FROM\n",
    "          corpus\n",
    "          \"\"\"\n",
    ")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97034ab2-3091-4bda-b1ca-5520808730f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create table\n",
    "df.write.saveAsTable(f\"{catalog_name}.{schema_name}.parsed_pdf_docs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "cbac216a-f2c8-4ab6-83ff-ad32ef605ab4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "parsed_records = spark.sql(f\"select element_at(split(split(path, ':')[1], '/'), -1) AS name, parsed from {catalog_name}.{schema_name}.parsed_pdf_docs\").collect()\n",
    "workspace_path = '/Workspace/Users/rohit.bhagwat@databricks.com/pdf-chat-bot/data/parsed_text/'\n",
    "for row in parsed_records:\n",
    "    with open(f\"{workspace_path}{row['name']}.txt\", \"w\") as file:\n",
    "        file.write(str(row['parsed']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "efcbea4d-b3d9-4ba7-b073-495978c03ccf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "target_volume = f'/Volumes/{catalog_name}/{schema_name}/{volume_name}/parsed/'\n",
    "for row in parsed_records:\n",
    "    with open(f\"{target_volume}{row['name']}.txt\", \"w\") as file:\n",
    "        file.write(str(row['parsed']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "87a0b5b0-3085-4faf-a12f-451903509143",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "01-extract-pdf",
   "widgets": {
    "catalog_name": {
     "currentValue": "rohitb_demo",
     "nuid": "34334499-fb33-4a85-a760-784bc6a902ef",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "rohitb_demo",
      "label": null,
      "name": "catalog_name",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "rohitb_demo",
      "label": null,
      "name": "catalog_name",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "schema_name": {
     "currentValue": "pdf_chat",
     "nuid": "674f24e3-be61-47ac-9a60-2acc71e9c1a1",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "pdf_chat",
      "label": null,
      "name": "schema_name",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "pdf_chat",
      "label": null,
      "name": "schema_name",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "volume_name": {
     "currentValue": "files",
     "nuid": "769abcef-96ab-4070-ba90-fc487b2dbbcf",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "files",
      "label": null,
      "name": "volume_name",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "files",
      "label": null,
      "name": "volume_name",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "workspace_folder": {
     "currentValue": "/Workspace/Users/rohit.bhagwat@databricks.com/pdf-chat-bot/data",
     "nuid": "f9397c31-3289-455c-97c3-71cc1ca112ad",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "/Workspace/Users/rohit.bhagwat@databricks.com/pdf-chat-bot/data",
      "label": null,
      "name": "workspace_folder",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "/Workspace/Users/rohit.bhagwat@databricks.com/pdf-chat-bot/data",
      "label": null,
      "name": "workspace_folder",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
